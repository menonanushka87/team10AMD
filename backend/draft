import json
import pandas as pd

def parse_sarif(file_path):
    """Parse the SARIF file to extract issue details."""
    with open(file_path, 'r') as file:
        sarif_data = json.load(file)

    issues = []

    for run in sarif_data['runs']:
        for result in run['results']:
            issue_details = {
                'rule_id': result.get('ruleId'),
                'file_path': result['locations'][0]['physicalLocation']['artifactLocation']['uri'],
                'line_number': result['locations'][0]['physicalLocation']['region']['startLine'],
                'message': result['message']['text']
            }
            issues.append(issue_details)

    return issues

def find_new_issues(baseline_issues, current_issues):
    """Compare issues between baseline and current to find new issues introduced."""
    baseline_df = pd.DataFrame(baseline_issues)
    current_df = pd.DataFrame(current_issues)

    new_issues = pd.merge(baseline_df, current_df, how='outer', indicator=True).query('_merge == "right_only"')

    return new_issues.drop(columns=['_merge'])

# Load baseline and a new commit's SARIF file
baseline_issues = parse_sarif("C:/Users/Asus/Downloads/database-5a7786812dd4-2024-01-11 (2)/database-b8b8ebcf851d-2017-04-11.sarif")
new_commit_issues = parse_sarif("C:/Users/Asus/Downloads/database-5a7786812dd4-2024-01-11 (2)/database-da5091bf507b-2019-08-02.sarif")

# Find new issues
new_issues = find_new_issues(baseline_issues, new_commit_issues)

# Display results
# print("Number of issues in baseline (2017):", len(baseline_issues))
# print("Number of issues in new commit (2019):", len(new_commit_issues))
# print("Number of new issues introduced in 2019:", len(new_issues))
# print("\nNew Issues Introduced:")
# print(new_issues[['rule_id', 'file_path', 'line_number', 'message']])
